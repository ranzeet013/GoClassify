{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6xr1rY4Klou",
        "outputId": "512f8093-6625-4f17-a80a-2da71d84b22c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "et-uVpszLu04"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "save_dir = '/content/drive/MyDrive/image-classifications/classification_results'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "print(f\"All results will be saved in: {save_dir}\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "with open(f'{save_dir}/device_info.txt', 'w') as f:\n",
        "    f.write(str(device))\n",
        "\n",
        "config = {\n",
        "    'batch_size': 64,\n",
        "    'learning_rate': 0.001,\n",
        "    'num_epochs': 10,\n",
        "    'model_architecture': 'FC-512-256-10',\n",
        "    'optimizer': 'Adam',\n",
        "    'loss_function': 'CrossEntropyLoss'\n",
        "}\n",
        "\n",
        "# Save config\n",
        "with open(f'{save_dir}/config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vdXCc14LzOq",
        "outputId": "fdb2d51a-82bf-4514-c0cb-3c6de2d53ab1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All results will be saved in: /content/drive/MyDrive/image-classifications/classification_results\n",
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# data loaders\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "bX6Mruf9L-sv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_sample_images(loader, save_path, num_images=8):\n",
        "    images, labels = next(iter(loader))\n",
        "    img_grid = torchvision.utils.make_grid(images[:num_images])\n",
        "    npimg = img_grid.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)).squeeze(), cmap='gray')\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "    os.makedirs(f'{save_dir}/sample_images', exist_ok=True)\n",
        "    for i in range(num_images):\n",
        "        img = images[i].squeeze().numpy()\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        im = Image.fromarray(img)\n",
        "        im.save(f'{save_dir}/sample_images/train_sample_{i}_label_{labels[i]}.png')\n",
        "\n",
        "save_sample_images(train_loader, f'{save_dir}/training_samples.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lePaJw8EMJtv",
        "outputId": "1dbe5722-2cf6-4622-d42a-6ea436dd6ee1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.42421296..2.8214867].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28*28, 512)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "baV7zglsMSWl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])"
      ],
      "metadata": {
        "id": "I69XfxaEMXsH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{save_dir}/model_architecture.txt', 'w') as f:\n",
        "    f.write(str(model))"
      ],
      "metadata": {
        "id": "LVEfLbLzMZXj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    history = {\n",
        "        'epoch': [],\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'epoch_time': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        history['epoch'].append(epoch + 1)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "        history['train_acc'].append(epoch_acc)\n",
        "        history['epoch_time'].append(epoch_time)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "              f'Loss: {epoch_loss:.4f}, '\n",
        "              f'Accuracy: {epoch_acc:.2f}%, '\n",
        "              f'Time: {epoch_time:.2f}s')\n",
        "\n",
        "    pd.DataFrame(history).to_csv(f'{save_dir}/training_history.csv', index=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['epoch'], history['train_loss'], label='Training Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['epoch'], history['train_acc'], label='Training Accuracy')\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.savefig(f'{save_dir}/training_curves.png')\n",
        "    plt.close()\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "fhwlnAbkMcB-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "train_history = train(model, train_loader, criterion, optimizer, config['num_epochs'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of6T6W3rMm81",
        "outputId": "e5737d6f-d283-40ae-c8c7-c4d2b76ff830"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch [1/10], Loss: 0.2051, Accuracy: 93.66%, Time: 14.66s\n",
            "Epoch [2/10], Loss: 0.0848, Accuracy: 97.39%, Time: 12.96s\n",
            "Epoch [3/10], Loss: 0.0610, Accuracy: 98.07%, Time: 12.88s\n",
            "Epoch [4/10], Loss: 0.0476, Accuracy: 98.44%, Time: 12.95s\n",
            "Epoch [5/10], Loss: 0.0402, Accuracy: 98.69%, Time: 12.99s\n",
            "Epoch [6/10], Loss: 0.0301, Accuracy: 99.00%, Time: 19.10s\n",
            "Epoch [7/10], Loss: 0.0289, Accuracy: 99.07%, Time: 16.84s\n",
            "Epoch [8/10], Loss: 0.0250, Accuracy: 99.23%, Time: 13.02s\n",
            "Epoch [9/10], Loss: 0.0219, Accuracy: 99.28%, Time: 12.99s\n",
            "Epoch [10/10], Loss: 0.0200, Accuracy: 99.32%, Time: 13.17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    all_probabilities = []\n",
        "    test_images = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        test_loss = 0.0\n",
        "\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_probabilities.extend(probabilities.cpu().numpy())\n",
        "            test_images.extend(images.cpu().numpy())\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        test_acc = 100 * correct / total\n",
        "\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n",
        "\n",
        "        test_metrics = {\n",
        "            'test_loss': test_loss,\n",
        "            'test_accuracy': test_acc,\n",
        "            'correct_predictions': correct,\n",
        "            'total_samples': total\n",
        "        }\n",
        "        with open(f'{save_dir}/test_metrics.json', 'w') as f:\n",
        "            json.dump(test_metrics, f, indent=4)\n",
        "\n",
        "        results_df = pd.DataFrame({\n",
        "            'true_label': all_labels,\n",
        "            'predicted_label': all_predictions,\n",
        "            'probabilities': list(all_probabilities)\n",
        "        })\n",
        "        results_df.to_csv(f'{save_dir}/test_predictions.csv', index=False)\n",
        "\n",
        "        os.makedirs(f'{save_dir}/test_images', exist_ok=True)\n",
        "        for i in range(min(20, len(test_images))):\n",
        "            img = test_images[i].squeeze()\n",
        "            img = (img * 255).astype(np.uint8)\n",
        "            im = Image.fromarray(img)\n",
        "\n",
        "            true_label = all_labels[i]\n",
        "            pred_label = all_predictions[i]\n",
        "            prob = max(all_probabilities[i]) * 100\n",
        "\n",
        "            im.save(f'{save_dir}/test_images/test_{i}_true_{true_label}_pred_{pred_label}_prob_{prob:.1f}.png')\n",
        "\n",
        "        return all_labels, all_predictions, all_probabilities, test_loss, test_acc"
      ],
      "metadata": {
        "id": "BMpajGqOMs0r"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating on test set...\")\n",
        "true_labels, pred_labels, probabilities, test_loss, test_acc = evaluate(model, test_loader)\n",
        "\n",
        "# classification report\n",
        "class_report = classification_report(true_labels, pred_labels, target_names=[str(i) for i in range(10)], output_dict=True)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, pred_labels, target_names=[str(i) for i in range(10)]))\n",
        "\n",
        "with open(f'{save_dir}/classification_report.json', 'w') as f:\n",
        "    json.dump(class_report, f, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5S2RY1yOQh0",
        "outputId": "670663c0-d58a-4129-d565-3ee72185561c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on test set...\n",
            "Test Loss: 0.1003, Test Accuracy: 97.82%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       980\n",
            "           1       0.99      0.98      0.99      1135\n",
            "           2       0.99      0.98      0.98      1032\n",
            "           3       0.97      0.98      0.97      1010\n",
            "           4       0.98      0.97      0.98       982\n",
            "           5       0.98      0.99      0.98       892\n",
            "           6       0.99      0.98      0.98       958\n",
            "           7       0.95      0.98      0.97      1028\n",
            "           8       0.96      0.98      0.97       974\n",
            "           9       0.98      0.95      0.96      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(true_labels, pred_labels)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=[str(i) for i in range(10)],\n",
        "            yticklabels=[str(i) for i in range(10)])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig(f'{save_dir}/confusion_matrix.png')\n",
        "plt.close()\n",
        "\n",
        "pd.DataFrame(conf_mat).to_csv(f'{save_dir}/confusion_matrix.csv')"
      ],
      "metadata": {
        "id": "NJJl0G7fPGgQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_test_predictions(test_loader, model, num_images=16):\n",
        "    model.eval()\n",
        "    images, labels = next(iter(test_loader))\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "    images = images.cpu()\n",
        "    labels = labels.cpu()\n",
        "    predicted = predicted.cpu()\n",
        "    probabilities = probabilities.cpu()\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "        prob_percent = probabilities[i][predicted[i]] * 100\n",
        "        plt.title(f'True: {labels[i]}\\nPred: {predicted[i]} ({prob_percent:.1f}%)')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{save_dir}/test_predictions_visualization.png')\n",
        "    plt.close()\n",
        "\n",
        "save_test_predictions(test_loader, model)"
      ],
      "metadata": {
        "id": "ph6xA291PIKH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), f'{save_dir}/classification_model_weights.pth')\n",
        "\n",
        "torch.save(model, f'{save_dir}/classification_model_full.pth')"
      ],
      "metadata": {
        "id": "KzkddUfFPNee"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}